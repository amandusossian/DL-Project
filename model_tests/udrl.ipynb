{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_size = 7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP UDPRL stolen from https://github.com/BY571/Upside-Down-Reinforcement-Learning/blob/master/Upside-Down.ipynb\n",
    "\n",
    "class BF(nn.Module):\n",
    "    def __init__(self, state_space, action_space, hidden_size, seed):\n",
    "        super(BF, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.actions = np.arange(action_space)\n",
    "        self.action_space = action_space\n",
    "        self.fc1 = nn.Linear(state_space, hidden_size)\n",
    "        self.commands = nn.Linear(2, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc5 = nn.Linear(hidden_size, action_space)\n",
    "\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=hidden_size, nhead=8)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=6)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, state, command):       \n",
    "               \n",
    "        out = self.sigmoid(self.fc1(state))\n",
    "        command_out = self.sigmoid(self.commands(command))\n",
    "        out = out * command_out\n",
    "        out = torch.relu(self.fc2(out))\n",
    "        out_ad = out.expand(1,-1,-1)\n",
    "        out = self.transformer_decoder(out_ad, out_ad)[0, :,:]\n",
    "\n",
    "        out = torch.relu(self.fc3(out))\n",
    "        out = torch.relu(self.fc4(out))\n",
    "        out = self.fc5(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def action(self, state, desire, horizon):\n",
    "        \"\"\"\n",
    "        Samples the action based on their probability\n",
    "        \"\"\"\n",
    "        command = torch.cat((desire,horizon), dim=-1)\n",
    "        action_prob = self.forward(state.expand(1, -1), command.expand(1, -1))[0,:]\n",
    "        probs = torch.softmax(action_prob, dim=-1)\n",
    "        action = torch.distributions.categorical.Categorical(probs=probs).sample()\n",
    "        return action\n",
    "    def greedy_action(self, state, desire, horizon):\n",
    "        \"\"\"\n",
    "        Returns the greedy action \n",
    "        \"\"\"\n",
    "        command = torch.cat((desire,horizon), dim=-1)\n",
    "        action_prob = self.forward(state, command)\n",
    "        probs = torch.softmax(action_prob, dim=-1)\n",
    "        action = torch.argmax(probs).item()\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "        \n",
    "        \n",
    "    def add_sample(self, states, actions, rewards):\n",
    "        episode = {\"states\": states, \"actions\":actions, \"rewards\": rewards, \"summed_rewards\":sum(rewards)}\n",
    "        self.buffer.append(episode)\n",
    "        \n",
    "    \n",
    "    def sort(self):\n",
    "        #sort buffer\n",
    "        random.shuffle(self.buffer)\n",
    "        # keep the max buffer size\n",
    "        self.buffer = self.buffer[:self.max_size]\n",
    "    \n",
    "    def get_random_samples(self, batch_size):\n",
    "        self.sort()\n",
    "        idxs = np.random.randint(0, len(self.buffer), batch_size)\n",
    "        batch = [self.buffer[idx] for idx in idxs]\n",
    "        return batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGame():\n",
    "    def __init__(self):\n",
    "        self.possibleStates = [0, 1, 2]\n",
    "        self.possibleActions = [0, 1]\n",
    "        self.state = 0\n",
    "        self.isTerminal = False\n",
    "        self.isLoss = False\n",
    "\n",
    "    def getState(self):\n",
    "        return np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]][self.state])\n",
    "    \n",
    "    def getReward(self):\n",
    "        if self.isTerminal:\n",
    "            if self.isLoss:\n",
    "                return -1\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    def getActions(self):\n",
    "        if self.isTerminal:\n",
    "            return []\n",
    "        return self.possibleActions\n",
    "\n",
    "    def action(self, a):\n",
    "        if a != 1 and a != 0:\n",
    "            a = 0\n",
    "        if a == 1:\n",
    "            if self.state == 0:\n",
    "                self.state = 1\n",
    "            elif self.state == 1:\n",
    "                self.state = 2\n",
    "                self.isTerminal = True\n",
    "        if a == 0:\n",
    "            if self.state == 0:\n",
    "                self.state = 2\n",
    "                self.isTerminal = True\n",
    "                self.isLoss = True\n",
    "            elif self.state == 1:\n",
    "                self.state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "bf = BF(3, 2, 64, 1).to(device)\n",
    "optimizer = optim.Adam(params=bf.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_desired_reward = 1\n",
    "init_time_horizon = 2\n",
    "\n",
    "def generate_episode(desired_return = torch.FloatTensor([init_desired_reward]), desired_time_horizon = torch.FloatTensor([init_time_horizon])):    \n",
    "    \"\"\"\n",
    "    Generates more samples for the replay buffer.\n",
    "    \"\"\"\n",
    "    g = SimpleGame()\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    while not g.isTerminal:\n",
    "        # random action\n",
    "        s = torch.from_numpy(g.getState()).float().to(device)\n",
    "        states.append(s)\n",
    "        a = bf.action(s, desired_return, desired_time_horizon)\n",
    "        g.action(a)\n",
    "        reward = g.getReward()\n",
    "        desired_return -= reward\n",
    "        desired_time_horizon -= 1\n",
    "        desired_time_horizon = torch.FloatTensor([np.maximum(desired_time_horizon, 1).item()])\n",
    "        actions.append(a)\n",
    "        rewards.append(reward)\n",
    "    return states, actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create replay buffer:\n",
    "buffer = ReplayBuffer(replay_size)\n",
    "\n",
    "# init replay buffer with random trajectories:\n",
    "for i in range(0, replay_size):\n",
    "    states, actions, rewards = generate_episode()\n",
    "    buffer.add_sample(states, actions, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# FUNCTIONS FOR TRAINING\n",
    "def select_time_steps(saved_episode):\n",
    "    \"\"\"\n",
    "    Given a saved episode from the replay buffer this function samples random time steps (t1 and t2) in that episode:\n",
    "    T = max time horizon in that episode\n",
    "    Returns t1, t2 and T \n",
    "    \"\"\"\n",
    "    # Select times in the episode:\n",
    "    T = len(saved_episode[\"states\"]) # episode max horizon \n",
    "    if T != 1:\n",
    "        t1 = np.random.randint(0,T)\n",
    "        t2 = np.random.randint(t1+1,T+1)\n",
    "    else:\n",
    "        t1 = 0\n",
    "        t2 = T\n",
    "\n",
    "    return t1, t2, T\n",
    "\n",
    "def create_training_input(episode, t1, t2):\n",
    "    \"\"\"\n",
    "    Based on the selected episode and the given time steps this function returns 4 values:\n",
    "    1. state at t1\n",
    "    2. the desired reward: sum over all rewards from t1 to t2\n",
    "    3. the time horizont: t2 -t1\n",
    "    \n",
    "    4. the target action taken at t1\n",
    "    \n",
    "    buffer episodes are build like [cumulative episode reward, states, actions, rewards]\n",
    "    \"\"\"\n",
    "    state = episode[\"states\"][t1] \n",
    "    desired_reward = sum(episode[\"rewards\"][t1:t2])\n",
    "    time_horizont = t2-t1\n",
    "    action = episode[\"actions\"][t1]\n",
    "    return state, desired_reward, time_horizont, action\n",
    "\n",
    "def create_training_examples(batch_size):\n",
    "    \"\"\"\n",
    "    Creates a data set of training examples that can be used to create a data loader for training.\n",
    "    ============================================================\n",
    "    1. for the given batch_size episode idx are randomly selected\n",
    "    2. based on these episodes t1 and t2 are samples for each selected episode \n",
    "    3. for the selected episode and sampled t1 and t2 trainings values are gathered\n",
    "    ______________________________________________________________\n",
    "    Output are two numpy arrays in the length of batch size:\n",
    "    Input Array for the Behavior function - consisting of (state, desired_reward, time_horizon)\n",
    "    Output Array with the taken actions \n",
    "    \"\"\"\n",
    "    input_array = []\n",
    "    output_array = []\n",
    "    # select randomly episodes from the buffer\n",
    "    episodes = buffer.get_random_samples(batch_size)\n",
    "    for ep in episodes:\n",
    "        #select time stamps\n",
    "        t1, t2, T = select_time_steps(ep)\n",
    "        # For episodic tasks they set t2 to T:\n",
    "        t2 = T\n",
    "        state, desired_reward, time_horizont, action = create_training_input(ep, t1, t2)\n",
    "        input_array.append(torch.cat([state, torch.FloatTensor([desired_reward]), torch.FloatTensor([time_horizont])]))\n",
    "        output_array.append(action)\n",
    "    return input_array, output_array\n",
    "\n",
    "def train_behavior_function(batch_size):\n",
    "    \"\"\"\n",
    "    Trains the BF with on a cross entropy loss were the inputs are the action probabilities based on the state and command.\n",
    "    The targets are the actions appropriate to the states from the replay buffer.\n",
    "    \"\"\"\n",
    "    X, y = create_training_examples(batch_size)\n",
    "\n",
    "    X = torch.stack(X)\n",
    "    state = X[:,0:3]\n",
    "    d = X[:,3:3+1]\n",
    "    h = X[:,3+1:3+2]\n",
    "    command = torch.cat((d,h), dim=-1)\n",
    "    y = torch.stack(y).long()\n",
    "    y_ = bf(state.to(device), command.to(device)).float()\n",
    "    optimizer.zero_grad()\n",
    "    pred_loss = F.cross_entropy(y_, y)   \n",
    "    pred_loss.backward()\n",
    "    optimizer.step()\n",
    "    return pred_loss.detach().cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_loop():\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        for _ in range(0, 10):\n",
    "            states, actions, rewards = generate_episode(torch.FloatTensor([1]), torch.FloatTensor([2]))\n",
    "            buffer.add_sample(states, actions, rewards)\n",
    "        \n",
    "        loss = train_behavior_function(replay_size*1)\n",
    "        print(i, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6918533\n",
      "2 0.6655031\n",
      "3 0.56628126\n",
      "4 0.6288855\n",
      "5 0.48809955\n",
      "6 0.49119264\n",
      "7 0.39312568\n",
      "8 0.37387088\n",
      "9 0.38383916\n",
      "10 0.3514984\n",
      "11 0.33018622\n",
      "12 0.3113203\n",
      "13 0.30211848\n",
      "14 0.30035645\n",
      "15 0.28957143\n",
      "16 0.28109035\n",
      "17 0.18923163\n",
      "18 0.255644\n",
      "19 0.23380806\n",
      "20 0.13778752\n",
      "21 0.26519132\n",
      "22 0.2870759\n",
      "23 0.27952635\n",
      "24 0.26584065\n",
      "25 0.2524954\n",
      "26 0.1256933\n",
      "27 0.121497735\n",
      "28 0.12586735\n",
      "29 0.12653805\n",
      "30 0.13082182\n",
      "31 0.12007605\n",
      "32 0.087930456\n",
      "33 0.056494035\n",
      "34 0.026977703\n",
      "35 0.019940365\n",
      "36 0.025105666\n",
      "37 0.017280852\n",
      "38 0.015297164\n",
      "39 0.0136148\n",
      "40 0.011188785\n",
      "41 0.009167238\n",
      "42 0.008833972\n",
      "43 0.0064627524\n",
      "44 0.005508576\n",
      "45 0.0050378735\n",
      "46 0.004147242\n",
      "47 0.0035999746\n",
      "48 0.0031798927\n",
      "49 0.008500742\n",
      "50 0.0025124135\n",
      "51 0.0022334082\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\iguti\\UNI\\Deep Learning\\Project\\yannik_scribble\\udrl.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m run_loop()\n",
      "\u001b[1;32mc:\\Users\\iguti\\UNI\\Deep Learning\\Project\\yannik_scribble\\udrl.ipynb Cell 11\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     states, actions, rewards \u001b[39m=\u001b[39m generate_episode(torch\u001b[39m.\u001b[39mFloatTensor([\u001b[39m1\u001b[39m]), torch\u001b[39m.\u001b[39mFloatTensor([\u001b[39m2\u001b[39m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     buffer\u001b[39m.\u001b[39madd_sample(states, actions, rewards)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m loss \u001b[39m=\u001b[39m train_behavior_function(replay_size\u001b[39m*\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(i, loss)\n",
      "\u001b[1;32mc:\\Users\\iguti\\UNI\\Deep Learning\\Project\\yannik_scribble\\udrl.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m command \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((d,h), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(y)\u001b[39m.\u001b[39mlong()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m y_ \u001b[39m=\u001b[39m bf(state\u001b[39m.\u001b[39;49mto(device), command\u001b[39m.\u001b[39;49mto(device))\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m pred_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(y_, y)   \n",
      "File \u001b[1;32mc:\\Users\\iguti\\.virtualenvs\\yannik_scribble-sRH0UPe6\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\iguti\\.virtualenvs\\yannik_scribble-sRH0UPe6\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\iguti\\UNI\\Deep Learning\\Project\\yannik_scribble\\udrl.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(out))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m out_ad \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mexpand(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_decoder(out_ad, out_ad)[\u001b[39m0\u001b[39m, :,:]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(out))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X13sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc4(out))\n",
      "File \u001b[1;32mc:\\Users\\iguti\\.virtualenvs\\yannik_scribble-sRH0UPe6\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\iguti\\.virtualenvs\\yannik_scribble-sRH0UPe6\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iguti\\.virtualenvs\\yannik_scribble-sRH0UPe6\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:460\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    457\u001b[0m tgt_is_causal \u001b[39m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[0;32m    459\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 460\u001b[0m     output \u001b[39m=\u001b[39m mod(output, memory, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask,\n\u001b[0;32m    461\u001b[0m                  memory_mask\u001b[39m=\u001b[39;49mmemory_mask,\n\u001b[0;32m    462\u001b[0m                  tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask,\n\u001b[0;32m    463\u001b[0m                  memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask,\n\u001b[0;32m    464\u001b[0m                  tgt_is_causal\u001b[39m=\u001b[39;49mtgt_is_causal,\n\u001b[0;32m    465\u001b[0m                  memory_is_causal\u001b[39m=\u001b[39;49mmemory_is_causal)\n\u001b[0;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    468\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32mc:\\Users\\iguti\\.virtualenvs\\yannik_scribble-sRH0UPe6\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\iguti\\.virtualenvs\\yannik_scribble-sRH0UPe6\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iguti\\.virtualenvs\\yannik_scribble-sRH0UPe6\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:848\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    846\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))\n\u001b[0;32m    847\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mha_block(x, memory, memory_mask, memory_key_padding_mask, memory_is_causal))\n\u001b[1;32m--> 848\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ff_block(x))\n\u001b[0;32m    850\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\iguti\\.virtualenvs\\yannik_scribble-sRH0UPe6\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:874\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._ff_block\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_ff_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 874\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear1(x))))\n\u001b[0;32m    875\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout3(x)\n",
      "File \u001b[1;32mc:\\Users\\iguti\\.virtualenvs\\yannik_scribble-sRH0UPe6\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\iguti\\.virtualenvs\\yannik_scribble-sRH0UPe6\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iguti\\.virtualenvs\\yannik_scribble-sRH0UPe6\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\iguti\\.virtualenvs\\yannik_scribble-sRH0UPe6\\lib\\site-packages\\torch\\nn\\functional.py:1266\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[0;32m   1265\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1266\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-26"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol = 0\n",
    "for x in buffer.get_random_samples(100):\n",
    "    lol += x['summed_rewards']\n",
    "lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 25)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, c = generate_episode(torch.FloatTensor([1]), torch.FloatTensor([25]))\n",
    "c[len(c)-1], len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_training_examples(7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 1] at entry 0 and [1] at entry 412",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\iguti\\UNI\\Deep Learning\\Project\\yannik_scribble\\udrl.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/iguti/UNI/Deep%20Learning/Project/yannik_scribble/udrl.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49mstack(y)\u001b[39m.\u001b[39mlong()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 1] at entry 0 and [1] at entry 412"
     ]
    }
   ],
   "source": [
    "torch.stack(y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yannik_scribble-sRH0UPe6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
